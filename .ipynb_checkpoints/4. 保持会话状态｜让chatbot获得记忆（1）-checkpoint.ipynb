{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f310313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt4\"\n",
    "model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f45ffa",
   "metadata": {},
   "source": [
    "# 回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc1a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMRequestsChain\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0, max_tokens=200)\n",
    "template = \"\"\"Between >>> and <<< are the raw search result text from google.\n",
    "Extract the answer to the question '{query}' or say \"not found\" if the information is not contained.\n",
    "Use the format\n",
    "Extracted:<answer or \"not found\">\n",
    ">>> {requests_result} <<<\n",
    "Extracted:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "  input_variables=[\"query\", \"requests_result\"],\n",
    "  template=template,\n",
    ")\n",
    "\n",
    "\n",
    "query_chain = LLMRequestsChain(llm_chain = LLMChain(llm=llm, prompt=PROMPT), output_key=\"query_info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f2c1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "translating_prompt_template = \"\"\"\n",
    "translate \"{query_info}\" into English:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "translating_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt=PromptTemplate.from_template(translating_prompt_template),\n",
    "    output_key = \"translated\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a427661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Sunny 29 / 19℃\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0, max_tokens=200)\n",
    "\n",
    "def overall(question):\n",
    "    inputs = {\n",
    "      \"query\": question,\n",
    "      # \"url\": \"http://www.baidu.com/s?wd=\" + question.replace(\" \", \"+\")\n",
    "      \"url\": \"https://cn.bing.com/search?q=\" + question.replace(\" \", \"+\")\n",
    "    }\n",
    "    \n",
    "    overall_chain = SequentialChain(\n",
    "        chains=[query_chain, translating_chain],\n",
    "        input_variables=[\"query\",\"url\"],\n",
    "        output_variables=[\"translated\"],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return overall_chain(inputs)[\"translated\"]\n",
    "\n",
    "overall(\"北京今天天气\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54124440",
   "metadata": {},
   "source": [
    "# 没有记忆的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df8a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def get_response(input):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment, # engine = \"deployment_name\".\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},   \n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        temperature = 0.9, \n",
    "        max_tokens = 200\n",
    "      )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0804701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作为一个人工智能，我不需要进行任何物理活动或休息。我24小时全天候为您提供服务，包括回答问题，设置提醒，播放音乐和更多。祝您今天的健身活动愉快！\n",
      "对不起，作为一个AI助手，我无法访问您的私人信息，包括您的健身日程，除非您以前告诉我。我重视用户的隐私和数据安全。\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"你好，今天是周二我要去健身，我一般每周二健身。你今天干什么？\"))\n",
    "print(get_response(\"我一般周几健身？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9a1d0",
   "metadata": {},
   "source": [
    "# 通过Gradio快速展示功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af13c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/83/07/5040f8b58b91e8a1053f0148a7b515329a2dfc17d74e62cc0871a2b9908e/gradio-3.42.0-py3-none-any.whl.metadata\n",
      "  Downloading gradio-3.42.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (22.1.0)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Obtaining dependency information for altair<6.0,>=4.2.0 from https://files.pythonhosted.org/packages/f2/b4/02a0221bd1da91f6e6acdf0525528db24b4b326a670a9048da474dfe0667/altair-5.1.1-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: fastapi in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (0.99.1)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.5.0 (from gradio)\n",
      "  Obtaining dependency information for gradio-client==0.5.0 from https://files.pythonhosted.org/packages/fe/85/ec0323f39192c4bee04e8e06e64213aff816b9d1b61c3c8367e75b1c7e10/gradio_client-0.5.0-py3-none-any.whl.metadata\n",
      "  Downloading gradio_client-0.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio)\n",
      "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/ec/91/e41f64f03d2a13aee7e8c819d82ee3aa7cdc484d18c0ae859742597d5aa0/httpx-0.24.1-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy~=1.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (1.24.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Obtaining dependency information for orjson~=3.0 from https://files.pythonhosted.org/packages/b7/63/1672c346745874576b3f53cdf1bba4e8e5854621b698f8a15aca9a490796/orjson-3.9.5-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
      "  Downloading orjson-3.9.5-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m347.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (23.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (1.10.12)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (2.31.0)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (4.7.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from gradio-client==0.5.0->gradio) (2023.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests~=2.0->gradio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests~=2.0->gradio) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click>=7.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
      "  Obtaining dependency information for httpcore<0.18.0,>=0.15.0 from https://files.pythonhosted.org/packages/94/2c/2bde7ff8dd2064395555220cbf7cba79991172bf5315a07eb3ac7688d9f1/httpcore-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sniffio in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mbj0593/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gradio-3.42.0-py3-none-any.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m867.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.1.1-py3-none-any.whl (520 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.6/520.6 kB\u001b[0m \u001b[31m651.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.5-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.6/243.6 kB\u001b[0m \u001b[31m560.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m259.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m524.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5580 sha256=a098a7a6996c3d9295079b262bf9bc69efdd1cf5a2299c83a172177cf2d1aa2b\n",
      "  Stored in directory: /Users/mbj0593/Library/Caches/pip/wheels/99/3b/84/22ac1eab7a10222ac6bbc3f7e69b04f3980db328978c533a3f\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, semantic-version, python-multipart, orjson, httpcore, httpx, altair, gradio-client, gradio\n",
      "Successfully installed altair-5.1.1 ffmpy-0.3.1 gradio-3.42.0 gradio-client-0.5.0 httpcore-0.17.3 httpx-0.24.1 orjson-3.9.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13092b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "        bot_message = get_response(message)\n",
    "        chat_history.append((message, bot_message)) #保存历史对话记录，用于显示\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #对话框\n",
    "    msg = gr.Textbox(label=\"Prompt\") #输入框\n",
    "    btn = gr.Button(\"Submit\") #提交按钮\n",
    "    #提交\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) \n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d6f45",
   "metadata": {},
   "source": [
    "# 提供外部记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d525ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "def get_response(msg):\n",
    "    # print(msg)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment, # engine = \"deployment_name\".\n",
    "        messages=msg,\n",
    "        temperature = 0.9, \n",
    "        max_tokens = 600\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74ee0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def history_to_prompt(chat_history): # 将对话内容保存在一个List里\n",
    "    msg = [{\"role\": \"system\", \"content\": \"You are an AI assistant.\"}]\n",
    "    i = 0\n",
    "    for round_trip in chat_history: # 将List里的内容，组成 ChatCompletion的 messages部分，{role，content} dict\n",
    "        msg.append({\"role\": \"user\", \"content\": round_trip[0]})\n",
    "        msg.append({\"role\": \"assistant\", \"content\": round_trip[1]})\n",
    "    return msg\n",
    "\n",
    "def respond(message, chat_history):\n",
    "    his_msg = history_to_prompt(chat_history) #并装历史会话，ChatCompletion的 messages部分格式\n",
    "    his_msg.append({\"role\": \"user\", \"content\": message}) # 放入当前用户问题\n",
    "    bot_message = get_response(his_msg)\n",
    "    chat_history.append((message, bot_message)) # 将用户问题和返回保存到 历史记录 List\n",
    "    return \"\", chat_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "492d60dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://7bce0d740a6c7f5adf.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7bce0d740a6c7f5adf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=480) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d5452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
