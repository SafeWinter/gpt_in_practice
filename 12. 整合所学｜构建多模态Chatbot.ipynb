{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2cfc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"gpt4\"\n",
    "model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b65ca7",
   "metadata": {},
   "source": [
    "# 回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c2a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: data/\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "embedding = OpenAIEmbeddings(deployment=\"embedding\",chunk_size=1)\n",
    "persist_directory = 'data/'\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"spotmax\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf29e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79e3325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0, max_tokens=200)\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"map_reduce\", retriever=vectordb.as_retriever(),return_source_documents=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b281920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input):\n",
    "    print(input)\n",
    "    result = qa({\"query\": input})\n",
    "    return result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "185c9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什么是MaxGroup？\n",
      "MaxGroup是根据服务⼯作模式和运⾏特征，优化主机群集的。智能弹性集群管理可以有效减少弹性计算资源波动（如：竞价实例的中断）带来的集群服务能⼒变化。并在⾯向成本优化构建的混合机型集群最⼤发挥集群不同机型的服务能⼒。\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"什么是MaxGroup？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c68c71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7878\n",
      "Running on public URL: https://d688dcc48dfd7ded6f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d688dcc48dfd7ded6f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=300) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68e807",
   "metadata": {},
   "source": [
    "# 从文本到图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e076eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to create an image based on the description provided.\n",
      "Action: create an image\n",
      "Action Input: a dog on the street\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import http.client\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def create_image(prompt):\n",
    "  api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "  api_version = api_version = '2022-08-03-preview'\n",
    "\n",
    "  url = \"{}dalle/text-to-image?api-version={}\".format(api_base, api_version)\n",
    "  headers= { \"api-key\": api_key, \"Content-Type\": \"application/json\" }\n",
    "  body = {\n",
    "      \"caption\": prompt,\n",
    "      \"resolution\": \"512x512\"\n",
    "  }\n",
    "  submission = requests.post(url, headers=headers, json=body)\n",
    "  operation_location = submission.headers['Operation-Location']\n",
    "  retry_after = submission.headers['Retry-after']\n",
    "  status = \"\"\n",
    "  while (status != \"Succeeded\"):\n",
    "      time.sleep(int(retry_after))\n",
    "      response = requests.get(operation_location, headers=headers)\n",
    "      status = response.json()['status']\n",
    "  image_url = response.json()['result']['contentUrl']\n",
    "  #display(Image(url=image_url))\n",
    "  return \"\\n![image](\"+image_url+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "229cbcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![image](https://dalleproduse.blob.core.windows.net/private/images/4cebd143-970c-40a8-a974-3b39e80c8b59/generated_00.png?se=2023-08-21T11%3A00%3A12Z&sig=3zoPA4f7x5ToH1RI8FjKjgT1Dca%2BXNl6X0JVe9tIZro%3D&ske=2023-08-27T01%3A44%3A42Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-08-20T01%3A44%3A42Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\n"
     ]
    }
   ],
   "source": [
    "print (create_image(\"A dog on the street.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259befa",
   "metadata": {},
   "source": [
    "# 构建多模态Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "73d3d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_spotmax_doc(input):\n",
    "    print(input)\n",
    "    result = qa({\"query\": input})\n",
    "    return result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b51061bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "from langchain.chains import LLMRequestsChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name = deployment, model_name=model, temperature=0.3, max_tokens=1000)\n",
    "\n",
    "# https://www.cnblogs.com/sunsky303/p/11045113.html\n",
    "\n",
    "def query_web(question):\n",
    "      template = \"\"\"Between >>> and <<< are the raw search result text from google.\n",
    "      Extract the answer to the question '{query}' or say \"not found\" if the information is not contained.\n",
    "      Use the format\n",
    "      Extracted:<answer or \"not found\">\n",
    "      >>> {requests_result} <<<\n",
    "      Extracted:\"\"\"\n",
    "\n",
    "      PROMPT = PromptTemplate(\n",
    "          input_variables=[\"query\", \"requests_result\"],\n",
    "          template=template,\n",
    "      )\n",
    "\n",
    "      inputs = {\n",
    "          \"query\": question,\n",
    "          \"url\": \"https://cn.bing.com/search?q=\" + question.replace(\" \", \"+\").replace(\"?\",\"\")\n",
    "      }\n",
    "      requests_chain = LLMRequestsChain(llm_chain = LLMChain(llm=llm, prompt=PROMPT), output_key=\"query_info\")\n",
    "      res = requests_chain.run(inputs)\n",
    "      print(f\"Result:{res}\")\n",
    "      return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4755e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Get current info\",func=query_web,\n",
    "        description=\"\"\"only invoke it when you need to answer questions about realtime info.\n",
    "             And the input should be a search query.\"\"\"),\n",
    "    Tool(\n",
    "        name=\"query spotmax doc\", func=query_spotmax_doc,\n",
    "        description=\"\"\"only invoke it when you need to get the info about spotmax/maxgroup/maxarch/maxchaos, \n",
    "        And the input should be the question.\"\"\"),\n",
    "    Tool(\n",
    "        name=\"create an image\", func=create_image,\n",
    "        description=\"\"\"invoke it when you need to create an image. \n",
    "        And the input should be the description of the image.\"\"\")\n",
    "]\n",
    "\n",
    "agent_chain = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", max_iterations=5,handle_parsing_errors=True,verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "baa87ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input):\n",
    "    return agent_chain.run(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5defa47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7886\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7886/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要先找到一些减脂食物的信息，然后根据这些食物创建一张早餐图片。\n",
      "Action: Get current info\n",
      "Action Input: 推荐减脂食物\u001b[0mhttp://cn.bing.com/search?q=推荐减脂食物\n",
      "Result:not found\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mnot found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我没有找到相关信息，我应该尝试使用不同的搜索词。\n",
      "Action: Get current info\n",
      "Action Input: 减脂食物列表\u001b[0mhttp://cn.bing.com/search?q=减脂食物列表\n",
      "Result:not found\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mnot found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mParsing LLM output produced both a final answer and a parse-able action:: 我还是没有找到相关信息，我可以根据我知道的一些减脂食物来回答这个问题。\n",
      "Final Answer: 一些好的减脂食物包括鸡胸肉、鸡蛋、燕麦、全麦面包、蔬菜和水果等。我将使用这些食物创建一张早餐图片。\n",
      "Action: create an image\n",
      "Action Input: 一张包含鸡胸肉、鸡蛋、燕麦、全麦面包、蔬菜和水果的早餐图片。\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3m我无法创建图片，但我已经给出了一些减脂食物的建议。\n",
      "Final Answer: 一些好的减脂食物包括鸡胸肉、鸡蛋、燕麦、全麦面包、蔬菜和水果等。抱歉，我无法创建图片。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m首先，我需要找到一些减脂食物的信息，然后根据这些食物来设计一份早餐，并生成相应的图片。\n",
      "Action: Get current info\n",
      "Action Input: 推荐减脂食物\u001b[0mhttp://cn.bing.com/search?q=推荐减脂食物\n",
      "Result:not found\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mnot found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我没有找到实时信息，我应该尝试使用一些常见的减脂食物来设计早餐。\n",
      "Action: create an image\n",
      "Action Input: 一个包含燕麦，鸡蛋，水果（如苹果，香蕉）和一杯无糖咖啡的早餐图片。\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "![image](https://dalleproduse.blob.core.windows.net/private/images/6ef775f7-edb5-4b82-8bfe-acef3a7f2bc9/generated_00.png?se=2023-08-22T02%3A46%3A33Z&sig=FglbdSwhuElDj5LOBiMhoymlLxyR0aLrtd4ZLLRr%2FUI%3D&ske=2023-08-26T08%3A59%3A38Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-08-19T08%3A59%3A38Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m我现在有了一张包含燕麦，鸡蛋，水果和无糖咖啡的早餐图片，这些都是常见的减脂食物。\n",
      "Final Answer: 这是我为你设计的减脂早餐，包括燕麦，鸡蛋，水果（如苹果，香蕉）和一杯无糖咖啡。这些食物都能帮助你减脂。![image](https://dalleproduse.blob.core.windows.net/private/images/6ef775f7-edb5-4b82-8bfe-acef3a7f2bc9/generated_00.png?se=2023-08-22T02%3A46%3A33Z&sig=FglbdSwhuElDj5LOBiMhoymlLxyR0aLrtd4ZLLRr%2FUI%3D&ske=2023-08-26T08%3A59%3A38Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2023-08-19T08%3A59%3A38Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=500) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e415d",
   "metadata": {},
   "source": [
    "# 给Agent添加记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c41748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(k=10, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6f6af5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "def get_response(input):\n",
    "    return agent_chain.run(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e0a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
