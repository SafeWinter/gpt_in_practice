{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fa1087",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting openai\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/64/bf/dffc041dd3d36d6b4624bde63d222c1735c525811e9fd6026397c612491d/aiohttp-3.8.6-cp39-cp39-win_amd64.whl (329 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ad\\anaconda3\\lib\\site-packages (from openai) (2.26.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ad\\anaconda3\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ad\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ad\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ad\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ad\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.7)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a6/a4/451ac414ebe15fd6b49a457c7e01f0a06f9b512c36e4388a9cfb26568fea/yarl-1.9.2-cp39-cp39-win_amd64.whl (61 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f9/16/ef36f5b20ee10dba86d4b5223d55b416e97dfa2dbf5546f0c6d9aa8a26ba/frozenlist-1.4.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f1/d2/d735d40355ce41f6d1c50a5d4feef47cd4aad0e2809dd2c8cb01601f04ac/multidict-6.0.4-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ad\\anaconda3\\lib\\site-packages (from aiohttp->openai) (21.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ad\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.4)\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.0 multidict-6.0.4 openai-0.28.1 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c034927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_TYPE\"]='azure'\n",
    "os.environ[\"OPENAI_API_VERSION\"]='2023-08-01-preview'\n",
    "os.environ[\"OPENAI_API_BASE\"]='https://chat-domo.openai.azure.com/'\n",
    "os.environ[\"OPENAI_API_KEY\"]='deafa3de05f44fff837a0d6f78b7a276'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08aa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = \"mygpt35\"\n",
    "model = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f410fa",
   "metadata": {},
   "source": [
    "# Hello GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5dd7f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个AI助理，没有具体的名字。你可以叫我助理或者任何你喜欢的名字。有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine = deployment, # 如果直接访问OpenAI GPT服务的同学，这里不要使用engine这个参数，要使用model，如： model=“gpt-4”\n",
    "    model = model, # for OpenAI \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个AI助理\"},   \n",
    "        {\"role\": \"user\", \"content\": \"你好！你叫什么名字？\"}\n",
    "    ],\n",
    "    temperature = 0.9, \n",
    "    max_tokens = 200,  \n",
    "    # n = 3\n",
    "  )\n",
    "print(response.choices[0].message.content)\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c95c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你好！我是AI助理，暂时还没有名字。你可以随意给我取一个名字，或者称呼我为AI助理即可。有什么我可以帮助你的吗？']\n"
     ]
    }
   ],
   "source": [
    "print([choice.message.content for choice in response.choices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3d9666-6bcd-46a9-9e8a-aae646c8a517",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e3397-2345-4e2c-95d7-2f2968176775",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54b967e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19000, 39442, 37507, 98806, 81543, 28037, 37507, 9554, 13646, 20022, 247, 3922, 60843, 31634, 19361, 17792, 24326, 232, 8676, 225, 6701, 249, 67178, 20834, 37507, 3922, 45932, 96, 19483, 17792, 51611, 76982, 21043, 98739, 1811]\n",
      "chinese:在未来还没有到来的时候，总要有人把它创造出来，那个人应该是我们。 ; 35 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "chinese = \"\"\"在未来还没有到来的时候，总要有人把它创造出来，那个人应该是我们。\"\"\"\n",
    "\n",
    "tokens = encoding.encode(chinese)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "num_of_tokens_in_chinese = len(encoding.encode(chinese))\n",
    "\n",
    "print(f\"chinese:{chinese} ; {num_of_tokens_in_chinese} tokens\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea48fe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7741, 107, 17792, 51043, 98, 14608, 102, 84264, 117, 3922, 30250, 229, 17905, 24273, 53283, 19361]\n",
      "Token size: 16\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "fn = tiktoken.encoding_for_model(model)\n",
    "tokenArr = fn.encode('斯人若彩虹，遇上方知有')\n",
    "print(tokenArr)\n",
    "print(f\"Token size: {len(tokenArr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ff07513-9537-4077-808d-0bde4400ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 斯人若彩虹，遇上方知有\n",
      "Translated text: If someone is like a rainbow, only when encountering them will you know they exist.\n",
      "\n",
      "Original token (size: 16): [7741, 107, 17792, 51043, 98, 14608, 102, 84264, 117, 3922, 30250, 229, 17905, 24273, 53283, 19361]\n",
      "Translated token (size: 17): [2746, 4423, 374, 1093, 264, 48713, 11, 1193, 994, 92372, 1124, 690, 499, 1440, 814, 3073, 13]\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Translate a Chinese text into English\n",
    "import openai\n",
    "raw_text = '斯人若彩虹，遇上方知有'\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine = deployment,\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are an experienced translator.'},\n",
    "        {'role': 'user', 'content': f'Translate the content into English and output the text only:{raw_text}'}\n",
    "    ],\n",
    "    temperature = 0.9,\n",
    "    max_tokens = 200,\n",
    "    # n = 3\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "print('Original text: ' + raw_text)\n",
    "print('Translated text: ' + answer)\n",
    "print()\n",
    "\n",
    "# Task 2: Compute the token size for both the original text and the translated version\n",
    "import tiktoken\n",
    "tool = tiktoken.encoding_for_model(model)\n",
    "tokenCh = tool.encode(raw_text)\n",
    "tokenEn = tool.encode(answer)\n",
    "print(f'Original token (size: {len(tokenCh)}): {tokenCh}')\n",
    "print(f'Translated token (size: {len(tokenEn)}): {tokenEn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd583aac-4d8f-4409-ba0c-206be202c99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
